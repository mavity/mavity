# Quadrupole Kernel Upgrade Plan

## Goal
Replace the current quadrupole kernel pipeline with the higher-performance traversal, integrator, and maintenance features from the monolithic quadrupole system.

## Traversal Upgrade (replace existing kernel traversal)

1. **Adopt texture-array hierarchy**  
   - Monolithic traversal binds three `TEXTURE_2D_ARRAY` uniforms (`u_levelsA0/A1/A2`) so all levels share three texture units @particle-system/gravity-quadrupole/traversal.js#34-47.  
   - Kernel version currently wires Level × Moment textures individually, consuming one sampler per attachment @particle-system/gravity-multipole/particle-system-quadrupole-kernels.js#268-284.  
   - **Action:** replace per-level WebGLTexture arrays with a trio of texture arrays owned by the system, mirroring monolithic allocation @particle-system/gravity-quadrupole/particle-system-quadrupole.js#365-454.

2. **Mirror MRT copy flow**  
   - Monolithic pipeline renders each level into 2D MRT targets, then copies the attachments into array layers via `copyTexSubImage3D` @particle-system/gravity-quadrupole/particle-system-quadrupole.js#397-454.  
   - Kernel aggregator/pyramid must be refactored to write into kernel-owned MRT FBOs and perform these layer copies after each pass to keep the texture-array data in sync.

3. **Reuse traversal shader logic**  
   - Legacy traversal computes uniforms for cell sizes, grid sizes, slices per row, and optional occupancy mask widths @particle-system/gravity-quadrupole/traversal.js#69-129.  
   - **Action:** port the fragment shader and uniform packing from monolithic traversal into a new `KTraversalQuadrupole` implementation that consumes texture arrays and (optionally) occupancy masks.

4. **Occupancy-aware variant**  
   - Maintain two traversal programs (with/without masks) as in monolithic `traversalQuadrupoleFrag(true|false)` @particle-system/gravity-quadrupole/particle-system-quadrupole.js#279-291.  
   - Runtime should select variant based on occupancy availability (see “Follow-up: GPU bounds & occupancy”).

## Integrator Upgrade (replace velocity/position kernels)

1. **Default integrator in demo**  
   - Demo bootstraps quadrupole mode by default @demo.js#83-175 and uses whatever integrator the selected pipeline exposes.  
   - Monolithic quadrupole runs Euler each frame (`buildQuadtree → clearForce → calculateForces → integratePhysics`) unless debug flag `useKDK` is set @particle-system/gravity-quadrupole/particle-system-quadrupole.js#616-652.  
   - KDK path swaps force textures and adds half-step kicks @particle-system/gravity-quadrupole/particle-system-quadrupole.js#658-692.

2. **Recommended kernel replacement**  
   - Build a consolidated integration kernel mirroring `integratePhysics` (Euler) to match current behavior.  
   - Velocity update must sample force texture plus current positions, apply damping, and clamp like monolithic GLSL @particle-system/utils/integrator.js#12-45.  
   - Position update should use the same shader logic @particle-system/utils/integrator.js#48-82.  
   - Defer KDK support to a future enhancement once the Euler kernel is in place.

## Additional system parity tasks

1. **World bounds update**  
   - Monolithic system periodically reads back positions to refresh world bounds via `updateWorldBoundsFromTexture` @particle-system/gravity-quadrupole/particle-system-quadrupole.js#622-633.  
   - Kernel version currently uses static bounds supplied at construction @particle-system/gravity-multipole/particle-system-quadrupole-kernels.js#47-58.

2. **Occupancy masks**  
   - Monolithic pipeline builds mask textures and arrays for traversal culling @particle-system/gravity-quadrupole/particle-system-quadrupole.js#465-469.  
   - Kernel version has no equivalent; once traversal is texture-array based, masks become required for performance parity.

## GPU World-Bounds & Occupancy Kernel

While adopting texture arrays from the monolithic system will fix resource consumption, we must NOT inherit its CPU readback bottleneck for bounds/occupancy updates. A GPU-based solution is critical.

### The Problem

Quadrupole simulation requires two pieces of metadata that update each frame:

1. **World bounds**: The min/max extent of all particles. Aggregation needs this to map particle coordinates to octree cells. Traversal needs it to compute cell sizes and perform MAC tests.

2. **Occupancy masks**: Binary flags indicating which octree cells contain particles. Traversal uses this to skip empty regions (typically 70-90% of cells).

**Current monolithic approach**: Read particle positions back to CPU, compute bounds/occupancy in JavaScript, upload back to GPU. This causes 10-100ms pipeline stalls.

**Kernel requirements**: Must compute both entirely on GPU without readback, storing results as textures that subsequent kernels can consume.

### The Conceptual Solution

Think of the particle system pipeline as a dataflow graph where kernels transform textures:

```
[Positions] → [Aggregation] → [Pyramid] → [Traversal] → [Forces]
                    ↓              ↓
              [Occupancy]    [Boundary trigger?]
      ↓
[BoundsReduce] (every N frames or when triggered)
      ↓
[Bounds texture]
```

We inject two new data streams:

**1. Bounds via scheduled reduction (Phase 1)**

Reduction is a classic parallel pattern: combine N values into 1 by recursively applying a merge operation. For bounds, merge = min/max of coordinates.

```
[N particles] → [N/16 local bounds] → [N/256 regional bounds] → ... → [2 global bounds]
```

**Execution strategy**: Run bounds reduction every 60-120 frames, NOT every frame. This balances:
- **Performance**: Reduction cost amortized over multiple frames
- **Accuracy**: Bounds drift slowly; frequent updates unnecessary
- **Robustness**: Uses only basic WebGL2 features (no MIN/MAX blending dependency)

Final output: 2 texels (min xyz, max xyz) stored in persistent texture. Aggregation/traversal sample this texture instead of reading uniforms.

**2. Boundary breach trigger (Phase 2 - safety mechanism)**

Problem: Scheduled updates (every 60 frames) miss explosive particle motion. Particles could escape world bounds between updates.

Solution: During aggregation, detect when particles land in outer voxel layers (boundary region). This doesn't require precise positions, just a boolean: "Are particles approaching edges?"

```
[Aggregation computes moments + occupancy]
       ↓
[Check: occupancy in outer 2-3 voxel layers?]
       ↓
[Write 1-bit flag to 1×1 trigger texture]
       ↓
[System samples trigger after aggregation]
       ↓
[If triggered → run BoundsReduce immediately, else wait for schedule]
```

**Key insight**: Trigger uses occupancy (which we're already computing), not positions. Minimal overhead: one boundary check per voxel, one texel output.

**3. Occupancy as aggregation byproduct**

Aggregation already scatters particles into grid cells and accumulates mass per cell. Occupancy is just: "did this cell receive any mass?"

```
[Aggregation computes moments]
       ↓
[Same pass writes: mass > threshold ? 1 : 0]
       ↓
[Packed binary mask texture]
```

Output: Bit-packed texture (32 cells per texel) that traversal samples to test occupancy before descending into a cell.

### How It Fits Into Kernel Architecture

**Kernel contract**: Each kernel owns its output textures, accepts input textures from other kernels. This solution follows that pattern:

**Phase 1: Scheduled bounds reduction**

- **New kernel** (`KBoundsReduce`): Accepts position texture, outputs 2×1 bounds texture. System runs this every 60-120 frames, NOT every frame.

- **Modified aggregation kernel**: Adds one output attachment for occupancy. Writes moment textures + occupancy texture simultaneously using MRT. (Phase 1: no trigger yet)

- **Modified traversal kernel**: Accepts two additional inputs (bounds texture, occupancy texture). Samples bounds to compute cell mapping. Tests occupancy bit before processing each cell.

**Phase 2: Add boundary trigger**

- **Aggregation enhancement**: During occupancy generation, check if particles land in outer voxel layers. Write 1-bit flag to 1×1 trigger texture.

- **System orchestration**: After aggregation, sample trigger texture. If boundary breach detected, run `KBoundsReduce` immediately instead of waiting for schedule.

**Data flow (Phase 1)**:
```
[Positions] → [BoundsReduce] (every 60-120 frames)
                    ↓
              [bounds texture] (persistent, sampled by aggregation/traversal)
                    ↓
[Positions] → [Aggregation] → [moments + occupancy textures]
                                      ↓
[Positions + moments + occupancy + bounds] → [Traversal] → [Forces]
```

**Data flow (Phase 2 - with trigger)**:
```
[Positions] → [Aggregation] → [moments + occupancy + trigger flag]
                    ↓                            ↓
              [moments/occupancy]    [Check: boundary breach?]
                                               ↓
                                    [Yes → run BoundsReduce now]
                                    [No  → wait for schedule]
```

All arrows are texture references. No CPU readback. No pipeline stalls.

### Why This Works for Kernels Specifically

**Amortized cost**: Running bounds reduction every 60-120 frames costs <1% of frame budget. Scheduled approach avoids per-frame overhead while maintaining accuracy.

**Safety without overhead**: Boundary trigger is essentially free - piggybacks on occupancy computation already happening in aggregation. Catches explosive motion without continuous monitoring.

**Resource efficiency**: Reduction produces tiny output (2 texels), occupancy is bit-packed (32× compression), trigger is 1 texel. Total overhead ~40KB for typical simulation.

**Composability**: Reduction kernel is reusable across systems. Mesh/spectral can use identical bounds reduction. Monopole can use for spatial hashing.

**GPU residency**: Bounds/occupancy stay GPU-side forever. System can run indefinitely without CPU touching particle data.

**Incremental adoption**: Phase 1 (scheduled bounds + occupancy) unblocks texture array conversion. Phase 2 (trigger) adds safety later without disrupting existing functionality.

### What Changes in Each Kernel (Conceptually)

**BoundsReduce** (new kernel - Phase 1):
- Input: position texture
- Algorithm: Hierarchical min/max reduction (N→N/16→...→2)
- Output: 2×1 texture containing (minX, minY, minZ, _) and (maxX, maxY, maxZ, _)
- Execution: System calls this every 60-120 frames, or immediately if trigger fires
- Robustness: Uses only basic WebGL2 features (no MIN/MAX blending)

**Aggregation** (two phases):
- **Phase 1**: Add 4th output for occupancy
  - Existing: Write 3 moment textures via MRT
  - Addition: Write occupancy texture tracking which cells received mass
  - Storage: Bit-packed into RGBA8 texture (32 cells per texel)
  
- **Phase 2**: Add boundary breach detection
  - During occupancy generation, check if voxel is in outer layers (x/y/z < 3 or > gridSize-3)
  - If boundary voxel has occupancy, set trigger flag
  - Write flag to 1×1 trigger texture (separate output, or use alpha channel of existing output)

**Pyramid** (no change):
- Already reduces moments hierarchically
- Occupancy and trigger stay at L0 (finest level), no need to reduce

**Traversal** (add inputs + culling):
- Existing: Sample position, level moments
- Addition: Sample bounds texture for world extent, sample occupancy texture before descending into cells
- Optimization: Skip branch if occupancy bit is 0 (expected 70-90% skip rate)

### Application Beyond Quadrupole

**Mesh/Spectral systems**: Need bounds to size grid appropriately. Currently use static bounds from initialization. With reduction kernel, can adapt grid dynamically as particles move.

**All systems**: Bounds enable GPU-driven view frustum culling, adaptive LOD, automatic domain decomposition for multi-GPU.

### Success Metrics

**Phase 1 complete when**:
1. Bounds texture updates every 60-120 frames without CPU readback
2. Aggregation/traversal sample bounds texture instead of uniforms
3. Traversal skips 70-90% of cells using occupancy (matches monolithic behavior)
4. Total GPU memory increase < 50KB (bounds + occupancy)
5. Frame budget improvement: eliminate 10-100ms stalls from CPU readback

**Phase 2 complete when**:
6. Boundary breach detected within 1 frame of particles approaching edges
7. Trigger causes immediate bounds recalc (bypassing schedule)
8. Trigger overhead < 0.1ms (essentially free with occupancy)
9. System handles explosive particle motion without particles escaping world bounds

