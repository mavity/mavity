# Markdown-based REPL as a chat

I have considered our work with REPL [see 7-http-test-harness.md](7-http-test-harness.md) and [7.1-file-test-harness.md](7.1-file-test-harness.md) and even [7.2-error-capture.md](7.2-error-capture.md) and realised that what would really smooth the file-based REPL is to turn it from transactional request-response to a log format. Or essentially chat format.

We should extend the file, keeping the past REPL interactions, and extending it down.

That way it will be way more useful for LLM: the file edit tools tend to struggle with content that is changing (timestamps in the lists) and also it will contain past interactions so it's easier to track what's happened.

The format should be based on Markdown of course. I have produced an example below ass a whole page in debug.md (note not debug.js anymore!):


# Connected pages:
* [7-zen-1201-03](http://localhost:8302/) last 22:02:12
* [12-dove-1631-13](http://localhost:8302/) last 22:52:48

**agent** to 12-dove at 22:52:47
```JS
12+13
```

**12-dove-1631-13** to agent at 22:52:48 (17ms)
```JSON
25
```

**agent** to 7-zen at 22:52:48
```JS
throw new Error("test error")
```

**7-zen-1201-03** to agent at 22:52:48 (**ERROR** after 16ms)
```Error
Error: test error
    at eval (eval at <anonymous> (http://localhost:8302/:112:37), <anonymous>:1:7)
    at inject (http://localhost:8302/:112:37)
```



**agent** to 7-zen at 22:53:49
```JS
await window._psys.loadSystem();
```

**7-zen-1201-03** to agent at 22:53:57  
executing ...


## Plan: human-first parsing & matching

This section turns the example above into a concrete, actionable plan for `serve.js` (or any parser) while preserving the human-first constraints: no job ids, no machine metadata, readable timestamps to the second, multiple concurrent jobs allowed, and flexible agent names.

### One-line goal
Keep the file fully human-readable while making it deterministic enough for an automated parser to match requests to replies using names, per-second timestamps, fences, and a nearest-prior-unmatched-request heuristic.

### Format rules (authoritative)
- Agent request header (exact):
    **<agent-name>** to <page-name> at HH:MM:SS
    ```JS
    <code...>
    ```
- Page reply header (accepted forms):
    - Immediate reply directly after request:
        **<page-name>** to <agent-name> at HH:MM:SS
    - Late or out-of-order reply (indicates the post time):
        **<page-name>** to <agent-name>(HH:MM:SS)
- Result fenced block follows the header; language tags: `JSON`, `Error`, `Text`, `JS`, etc.
- Timestamps are human per-second `HH:MM:SS`. If missing, parsers may use file-modify time as fallback.

### Parsing principles
- Stateless full-file parse on each change: scan left→right for header+fenced-block pairs and build two ordered lists: requests[] and replies[].
- Normalize line endings to `\n` and trim trailing spaces when parsing fences.
- Only accept a request when its code fence is closed (ignore incomplete/draft fences).

### Matching algorithm (deterministic, human-first)
1. Parse file into events:
     - request: { kind:'req', agent, page, time (seconds-of-day), code, pos, checksum }
     - reply: { kind:'reply', page, agent, time (seconds-of-day), lang, content, pos }
2. For each reply, find candidate requests where req.page === reply.page and (req.agent === reply.agent OR reply.agent is the generic token `agent`).
3. From candidates choose the request with the largest req.time that is <= reply.time (nearest prior unmatched request).
4. Tie-breakers (same-second collisions):
     - Prefer the earliest unmatched request with identical checksum hint if present (encourage a one-line human token in the request to help disambiguate).
     - Otherwise pick FIFO (earliest unmatched) and flag the match as same-second ambiguous for human review.
    - Implementation disambiguation rule: when the server detects possible same-second collisions for requests/replies, it will deliberately wait an extra second before recording the reply time (or before writing its acknowledgement) so that replies are recorded at a later second and become unambiguous. This behavior should be noted in logs and made configurable (e.g., `disambiguationDelaySec = 1`) so local workflows can opt-out.
5. If no prior candidate exists, allow a controlled heuristic: match to the most recent unmatched request for that page (mark as heuristic/clock-skew), or leave reply as orphan for manual reconciliation.

Notes:
- This supports concurrent queued requests to the same page. Replies match to the nearest prior unmatched request by time.
- Mark ambiguous or heuristic matches in logs/console so humans can inspect and optionally correct.

### Duration presentation
- Compute duration from parsed per-second timestamps: duration = reply.time - req.time (in seconds). Present to humans as `~Ns` or `<1s` where appropriate. Do not write machine ms values into the file; keep the file human-centric.

### Optional lightweight hints (keep human-first)
- Encourage short one-line comments in requests as human tokens, e.g. `// run: load-spectral` to help disambiguation.
- Use consistent agent names when possible; parser will extract whatever label is used.

### Edge cases and recommended handling
- Same-second collisions: encourage a brief wait between submissions or use the optional hint comment to reduce ambiguity.
    - Implementation note: the server may apply a small automatic delay (default 1s) to intentionally stagger recorded times so collisions are less likely. This delay is only for recording/acknowledgement and should be visible in server logs; the file remains human-first.
- Partial/incomplete fences: treat as drafts; do not dispatch.
- Editor rewrites and top-strip: parse whole file each time; do not rely on offsets.
- Orphan replies: keep them in the file and surface via `serve.js` console for manual matching.
- Late results (post-timeout): accept but mark `late` or `timeout` in server logs; append the reply normally in the file.
- Large or binary outputs: archive full payloads to an `debug-archive/` path and include a small human summary in the chat.

### UX recommendations
- When sending many concurrent requests to the same page, add a unique human token comment to each request block to avoid ambiguity.
- For long-running jobs, put a visible note in the request like `/* long-run */` so late replies are expected.
- Keep agent naming consistent for clean mapping between agent and replies.

### Minimal test matrix
- Parse happy path: single request → immediate reply.
- Concurrent requests: two requests in same second → replies arrive in reverse order → parser uses nearest-prior rule and flags ambiguous matches.
- Incomplete fence: request saved without closing fence → parser ignores it.
- Reply without timestamp: parser uses file-modify fallback and marks the match as fallback-timestamp.
- Orphan reply: reply exists with no plausible prior request → show as orphan.

### Quick checklist (copy into a TODO in repo)
- [ ] Stateless parser: extract requests and replies (fenced-block aware).
- [ ] Matching algorithm implementation with ambiguity flags.
- [ ] Console/logging of matched pairs, heuristics, and orphans.
- [ ] Archive mechanism for large results.
- [ ] Tests for the minimal matrix above.
- [ ] UX notes in `docs/7.3-repl-chat.md` (this section).

## Final notes
This plan keeps the file readable and friendly to LLMs while providing a deterministic, explainable set of heuristics to match replies to requests without machine metadata. If you want, I can now implement the parser in a compact `scripts/debug-md-parser.js` with unit tests and a small CLI to run against a sample `debug.md` for validation.

