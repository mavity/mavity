# Plan A: Linear Octree (LBVH) with Morton Order

[See Plans and alternatives](4-refactoring-options.md) for context.

This document provides a **high-level conceptual plan** for implementing Plan A: replacing the current uniform voxel pyramid with a **Linear Bounding Volume Hierarchy (LBVH)** built from **Morton-encoded particle positions**. This is the classic GPU-friendly adaptive octree structure used in ray tracing and spatial acceleration.

---

## 0) Core Concept & Goals

### What is LBVH/Morton Order?

A **Linear Octree** is a flat array representation of an octree where:
- Particles are sorted by **Morton codes** (Z-order space-filling curve)
- Tree structure is implicit in the sorted order via **Longest Common Prefix (LCP)**
- Nodes are stored in linear textures, not pointer-based structures

**Morton encoding** interleaves the bits of (x, y, z) coordinates to create a 1D key that preserves spatial locality. Particles close in 3D space have similar Morton codes.

### Why This Helps

**Current system issues:**
- Fixed uniform grid wastes memory in sparse regions
- Fixed neighborhood stencils visit many empty cells
- Summation order varies frame-to-frame causing numerical drift

**LBVH advantages:**
- **Adaptive**: hierarchy matches particle distribution
- **Coherent traversal**: Morton order ensures cache-friendly access patterns
- **Stable**: sorting provides consistent tree topology between frames
- **GPU-native**: flat arrays suit GPU memory model
- **Scalable**: same complexity as BH but better constants

---

## 1) High-Level Pipeline Overview

Replace the current `buildQuadtree() → traversal` with:

```
1. Morton Encoding     (positions → Morton keys)
2. Radix Sort          (keys → sorted order)
3. Tree Construction   (sorted keys → node hierarchy via LCP)
4. Multipole Refit     (leaf→root: compute mass, COM, optional quadrupole)
5. Stackless Traversal (evaluate forces using flat node array)
6. Integration         (reuse existing velocity/position updates)
```

**Key difference from current system**: 
- No uniform grid aggregation
- No pyramid reduction
- Tree adapts to particle distribution
- Traversal uses node pointers instead of fixed stencils

---

## 2) Morton Encoding Stage

### Purpose
Convert 3D floating-point positions into 1D integer keys that preserve spatial locality.

### Algorithm

**Input**: Particle positions `(x, y, z)` in world space  
**Output**: Morton codes (30-bit or 60-bit integers)

**Process**:
1. **Normalize positions** to unit cube [0, 1)³ using world bounds
2. **Quantize** to L-bit integers per axis (e.g., L=10 for 30-bit total, L=20 for 60-bit)
3. **Bit-interleave** the three coordinates: `morton = interleave(ix, iy, iz)`

**Bit interleaving** (Z-order curve):
```
For each bit position b from 0 to L-1:
  output[3*b + 0] = x[b]
  output[3*b + 1] = y[b]
  output[3*b + 2] = z[b]
```

### Spatial Properties

- Siblings in octree differ in lowest 3 bits
- Parent differs in lowest 3k bits from grandchildren at depth k
- Spatial neighbors have similar high-order bits

### Data Layout

**Shader output**: One Morton key per particle stored in texture
- **30-bit keys**: Pack into R32UI or RG16UI
- **60-bit keys**: Pack into RG32UI (two 32-bit uints)

**Precision considerations**:
- 10 bits/axis = 1024³ resolution (adequate for most cases)
- 20 bits/axis = 1048576³ resolution (overkill but future-proof)

### Existing Reuse

- World bounds from current system
- Position texture layout (same particle addressing)
- Fullscreen quad or point-draw paradigm

---

## 3) Radix Sort Stage

### Purpose
Sort particles by Morton key to establish spatial coherence and enable LCP-based tree construction.

### Algorithm Choice: LSD Radix Sort

**Why radix sort**:
- O(k·N) where k = number of digits (passes)
- Perfectly parallel per pass
- Stable (preserves order within equal keys)
- Well-suited for GPU with scan primitives

**High-level process**:
1. Choose digit size (4-8 bits recommended)
2. For each digit position (least significant to most):
   - **Histogram**: count occurrences of each digit value
   - **Prefix scan**: compute output offsets
   - **Scatter**: write particles to sorted positions
3. Repeat for all digit positions

### Implementation Approach

**Per-pass structure**:
- **Histogram pass**: Reduce to digit counts (256 bins for 8-bit digits)
- **Scan pass**: Exclusive prefix sum over histogram (can use existing reduction pattern)
- **Permute pass**: Scatter particles to new locations based on scan results

**Data management**:
- Ping-pong between two full-size particle buffers (positions, velocities, keys)
- Or: maintain index buffer and reorder once at end

**Number of passes**:
- 30-bit keys with 8-bit digits: 4 passes
- 60-bit keys with 8-bit digits: 8 passes

### Scan Primitive

**Parallel prefix sum** (already available pattern):
- Current system has reduction passes in `reduction.frag.js`
- Adapt for exclusive scan (output[i] = sum of elements before i)
- Can use work-efficient up-sweep/down-sweep or simpler hierarchical approach

### Stability Considerations

Sort should be **stable** to maintain consistent ordering when particles have identical keys (same voxel). This ensures reproducible tree structure frame-to-frame.

---

## 4) Linear Octree Construction via LCP

### Purpose
Build hierarchical tree structure by identifying parent-child relationships in the sorted Morton sequence.

### Core Insight: Longest Common Prefix

In a sorted Morton sequence, tree structure is implicit:
- Particles with identical high-order bits share common ancestors
- Length of common prefix determines depth of their lowest common ancestor
- Each internal node corresponds to a range of particles

### Karras LBVH Algorithm

**For each particle i in sorted order**:
1. Compute **direction**: which neighbor (i-1 or i+1) has longer common prefix
2. Find **split position**: binary search for extent of common prefix
3. Determine **parent/child links**: based on prefix lengths

**Key operations**:
- `delta(i,j)` = length of common prefix between keys[i] and keys[j]
- `clz(x)` = count leading zeros (gives prefix length from XOR)

**Node data per internal node**:
- Range: [first_particle, last_particle]
- Split index: where left subtree ends
- Parent pointer (or implicit from array index)
- Child pointers: left and right

### Data Structure Layout

**Leaf nodes** (N particles):
- One per particle
- Stores particle index into original position/velocity arrays

**Internal nodes** (N-1 nodes):
- Binary tree structure
- Stores range, split, and multipole data

**Texture packing**:
- Nodes stored in flat texture array
- Each node = several texels (4-8 components per texel)
- Example: `node = {rangeStart, rangeCount, leftChild, rightChild, mass, COM.xyz, ...}`

### Construction Pass

**Single fullscreen pass per internal node**:
- Each fragment computes one internal node
- Reads sorted Morton keys
- Computes delta values and determines split
- Writes node structure

**Parallelization**: All N-1 internal nodes can be built in parallel since they only read the sorted keys.

---

## 5) Multipole Refit Stage

### Purpose
Bottom-up pass to compute physical quantities (mass, center of mass, optional quadrupole moments) for each node from its children.

### Algorithm

**Leaf nodes**: Copy directly from particle data
```
mass = particle.mass
COM = particle.position
(optionally compute zero quadrupole)
```

**Internal nodes**: Sum from two children
```
mass = left.mass + right.mass
COM = (left.mass * left.COM + right.mass * right.COM) / mass
quadrupole = sum of child quadrupoles + parallel axis theorem terms
```

### Execution Strategy

**Dependency**: Parents depend on children being computed first

**Option 1 - Level-by-level**:
- Identify depth of each node
- Process in waves from deepest to root
- Multiple passes, each doing one level

**Option 2 - Atomic aggregation**:
- Each node atomically adds to parent when complete
- Requires atomic operations on float textures
- Single pass but less efficient

**Option 3 - Iterative convergence**:
- Multiple passes over all nodes
- Each pass, nodes read children and write self
- Converges in log(depth) passes

**Recommendation**: Option 1 (level-by-level) is cleanest and matches current reduction pattern.

### Multipole Data

**Monopole** (always):
- Total mass
- Center of mass (3 components)

**Quadrupole** (optional, for accuracy):
- 6 unique components of symmetric 3×3 tensor
- Requires second moments: ∑m·x², ∑m·xy, etc.
- Can be computed from children's quadrupoles + translation terms

**Storage per node**:
- Monopole: 4 floats (mass + COM.xyz)
- Quadrupole: 6 floats (Q_xx, Q_yy, Q_zz, Q_xy, Q_xz, Q_yz)
- Additional metadata: node size/bounds (for MAC)

---

## 6) Stackless Traversal for Force Evaluation

### Purpose
Replace fixed-neighborhood stencil with adaptive tree traversal guided by Barnes-Hut opening criterion.

### Stackless Traversal Pattern

**Challenge**: Fragment shaders have limited stack depth or no explicit stack.

**Solution**: Stackless traversal using restart trail or parent pointers:

**Method 1 - Restart trail**:
```
current = root
while current is not null:
  if should_open(current):
    current = left_child
  else:
    accumulate_force(current)
    current = next_sibling_or_ancestor
```

**Method 2 - Parent pointers**:
```
current = root
while not done:
  if should_open(current):
    descend to left child
  else:
    accumulate force
    ascend and move to next sibling
```

**Key**: Navigation uses only node index arithmetic and parent/sibling links stored in node data.

### Opening Criterion (MAC)

**Current system**: Simple `s/d < θ` where s=cell size, d=distance to target.

**Improved for LBVH**:
```
should_open = (distance < node_size/θ + COM_offset)
```

Where `COM_offset` is distance from node's COM to its geometric center. This is the **improved MAC** from Plan C, naturally fits with LBVH since we track actual extents.

**When to open (descend)**:
- Node too close to particle
- Node too large relative to distance
- Node contains very few particles (can optimize with direct sum)

**When to accept (use multipole)**:
- Node far enough and small enough
- Use monopole or monopole+quadrupole approximation

### Force Accumulation

**Per particle** (each fragment):
1. Start at root node
2. Traverse tree with opening criterion
3. For accepted nodes: compute force from multipole
4. For opened nodes: recurse to children
5. Accumulate total force to output texture

**Force kernel**:
- **Monopole**: Standard `F = G·m1·m2·r/|r|³` with softening
- **Quadrupole**: Add correction terms from quadrupole tensor
- Same math as current `traversal-quadrupole.frag.js` but with LBVH nodes

### Memory Access Pattern

**Advantage of Morton order**: 
- Particles processed in Morton order
- Their spatial neighbors are stored nearby
- Tree nodes accessed in coherent patterns
- Better texture cache utilization than random access

**Optimization**: Process particles in sorted Morton order to maximize coherence.

---

## 7) Integration with Existing System

### What to Keep

**Unchanged**:
- Position and velocity textures (ping-pong)
- Color texture
- Velocity and position integration shaders (`vel_integrate.frag.js`, `pos_integrate.frag.js`)
- Rendering pipeline
- GPU profiler infrastructure
- Debug helpers (`unbindAllTextures`, `checkGl`, `checkFBO`)

**Same concepts, different data**:
- World bounds (still needed for Morton encoding)
- Particle texture addressing (same layout)
- Force accumulation texture (write forces, then integrate)

### What to Replace

**Remove**:
- Uniform grid aggregation (`aggregation.vert.js`, `aggregation.frag.js`)
- Pyramid reduction (`reduction.frag.js`)
- Fixed-neighborhood traversal (`traversal.frag.js`)
- Multi-level grid textures

**Add**:
- Morton encoding pass
- Radix sort infrastructure (histogram, scan, permute)
- LCP-based tree construction pass
- Bottom-up refit pass
- Stackless LBVH traversal pass

### Coexistence Strategy

Implement LBVH as **parallel system** initially:
- Add `method: 'lbvh'` option alongside `'quadrupole'`, `'spectral'`, `'mesh'`
- Reuse position/velocity/force textures
- Different force computation path
- Same integration and rendering

This allows A/B testing and gradual migration.

---

## 8) Data Structure Reference

### Morton Key Storage

**Per particle**:
- Morton code: 32 or 64 bits
- Particle ID: original index (for position/velocity lookup)

**Texture format**: RG32UI or RGBA32UI

### Sorted Particle Arrays

**After sort**:
- Positions in Morton order (optional, can use index indirection)
- Velocities in Morton order (optional)
- Morton keys in sorted order (required)
- Particle IDs in sorted order (required for indirection)

### Tree Node Storage

**Leaf nodes** (one per particle):
```
particleID: index into position/velocity textures
mass: from position.w
position: from position.xyz
(implicit: leaf nodes are indices N to 2N-1)
```

**Internal nodes** (N-1 nodes):
```
rangeStart: first particle index in this subtree
rangeCount: number of particles in this subtree
leftChild: index of left child node
rightChild: index of right child node
mass: total mass of subtree
COM: center of mass (x, y, z)
(optional) quadrupole: 6 tensor components
(optional) size: bounding box or radius for MAC
```

**Texture packing**: Each node spans multiple texels. Example:
- Texel 0: `{rangeStart, rangeCount, leftChild, rightChild}`
- Texel 1: `{mass, COM.x, COM.y, COM.z}`
- Texel 2: `{Q_xx, Q_yy, Q_zz, Q_xy}` (if using quadrupoles)
- Texel 3: `{Q_xz, Q_yz, size, reserved}`

---

## 9) Algorithm Specifications

### 9.1 Morton Encoding Details

**Bit interleaving function**:
For 30-bit Morton code from 10-bit (x,y,z):
```
morton = 0
for bit b from 0 to 9:
  morton |= ((x >> b) & 1) << (3*b + 0)
  morton |= ((y >> b) & 1) << (3*b + 1)
  morton |= ((z >> b) & 1) << (3*b + 2)
```

**LUT optimization**: Precompute interleaving for 8 or 10-bit chunks, use table lookup instead of bit-by-bit.

**Precision**: Ensure world bounds are frozen or updated infrequently. Morton codes become meaningless if bounds change significantly.

### 9.2 Radix Sort Details

**8-bit digit radix sort** (4 passes for 32-bit keys):

**Pass k** (processes digit at position k*8):
1. **Local histogram**: Each workgroup counts local digit frequencies
2. **Global histogram**: Reduce local histograms to global counts
3. **Prefix scan**: Exclusive scan over 256 bins
4. **Scatter**: Each particle reads digit, looks up offset, writes to new position

**Scan algorithm**: Use work-efficient Blelloch scan or hierarchical scan similar to reduction pattern.

**Stability**: Use stable scatter (within same digit, preserve original order).

### 9.3 LCP Construction Details

**Delta function**:
```
delta(i, j):
  if i or j out of bounds: return -1
  if keys[i] == keys[j]: return 64 + clz(i XOR j)  // tie-break by index
  return clz(keys[i] XOR keys[j])                  // count leading zeros
```

**For each internal node i** (parallel):
```
1. Determine direction d = sign(delta(i+1) - delta(i-1))
2. Find minimum delta_min with neighbor at i+d
3. Binary search for length l where delta(i, i+l*d) > delta_min
4. Split at s = i + l*d where delta(i,s) is maximum in range
5. Set leftChild = (d>0) ? i : s, rightChild = (d>0) ? s : i
```

This constructs a binary tree where each internal node represents the merge point of two subtrees.

### 9.4 Traversal Details

**Pseudocode** (per particle):
```
target_position = read from position texture
force = (0, 0, 0)
stack or iteration state = root node

while traversal not complete:
  current_node = get next node to consider
  
  if current_node is leaf:
    r = target_position - leaf_position
    if |r| > 0:  // skip self
      force += monopole_force(r, leaf_mass)
    move to next node
    
  else:  // internal node
    r = target_position - node_COM
    d = |r|
    s = node_size
    
    if should_open(d, s, theta):
      descend to left child
    else:
      force += multipole_force(r, node_mass, node_COM, node_quadrupole)
      move to next node (sibling or ancestor)

write force to force texture
```

**Multipole force evaluation**: Same physics as current system, use formulas from `traversal-quadrupole.frag.js`.

---

## 10) Comparison with Current System

### Current Pyramid System

**Structure**:
- Uniform 64³ L0 grid → 32³ → 16³ → 8³ → 4³ → 2³ → 1³
- Fixed 8 levels regardless of particle distribution
- 85,000+ voxels total (sum of geometric series)

**Traversal**:
- Fixed neighborhood stencils (3³ or 5³)
- Many empty cells visited
- Order varies with particle position

**Memory**:
- All levels allocated regardless of occupancy
- ~85K voxels × (mass + COM + quadrupole) = substantial

### LBVH System

**Structure**:
- 2N-1 nodes total (N particles)
- Depth varies by local density (4-20 typical)
- No empty nodes

**Traversal**:
- Adaptive descent based on MAC
- Skip empty regions entirely
- Consistent Morton order

**Memory**:
- Exactly 2N-1 nodes (linear in particle count)
- Better asymptotic scaling

### Complexity Analysis

**Current system**:
- Build: O(N) aggregation + O(G) reduction where G ≈ 85K
- Traversal: O(N·k·L) where k=stencil size, L=levels

**LBVH**:
- Encode: O(N)
- Sort: O(N log N) or O(k·N) for radix
- Build: O(N)
- Refit: O(N)
- Traversal: O(N log N) average, O(N²) worst (all particles in same region)

**Practical advantage**: Constants are better, memory coherence is better, adaptive is better for non-uniform distributions.

---

## 11) Barnes-Hut Physics Preservation

### Unchanged Physics

The actual force computation remains **identical**:
- Monopole approximation: `F = G·m·M·r/|r|³`
- Quadrupole correction (if enabled): same tensor math
- Softening: same epsilon parameter
- Opening criterion: improved but fundamentally same idea

### What LBVH Changes

**Only the data structure**, not the physics:
- How we organize particles spatially
- How we navigate to find relevant interactions
- How we store and access multipole moments

**Result**: Forces should be numerically similar (within floating-point precision) to current system with same theta.

### Validation Path

Easy to verify correctness:
1. Run same particle configuration with both methods
2. Compare force outputs at same theta
3. Should agree to numerical precision
4. Differences only from:
   - Different tree topology (adaptive vs uniform)
   - Different traversal order (Morton vs grid order)
   - Improved MAC if using COM offset

---

## 12) Near-Field / L0 Direct Sum

### Purpose
LBVH handles far-field through multipole expansion. For particles in immediate neighborhood, direct sum may be more accurate.

### Integration Options

**Option 1**: Pure LBVH, descend to leaves
- Traverse to leaf nodes containing nearby particles
- Compute particle-particle interactions directly
- No separate near-field pass

**Option 2**: Hybrid LBVH + grid near-field
- Keep simplified L0 grid for near-field only
- Use LBVH for far-field (nodes beyond ~3 cells)
- Combine forces from both

**Option 3**: No explicit near-field
- Rely on LBVH to descend as deep as needed
- With small theta, naturally evaluates close interactions directly
- Softening handles very close encounters

**Recommendation**: Start with Option 1 (pure LBVH), add Option 2 only if near-field accuracy becomes an issue.

---

## 13) Memory and Performance Considerations

### Memory Footprint

**Morton keys**: N × 4-8 bytes
**Sorted indices**: N × 4 bytes  
**Tree nodes**: (2N-1) × ~64 bytes (with quadrupoles)
**Temporary sort buffers**: 2× particle data during sort

**Total**: ~150 bytes per particle (comparable to current system's pyramid)

**Advantage**: Linear scaling. Current system allocates for all 85K voxels regardless of N.

### Performance Bottlenecks

**Sort** (4-8 passes):
- Histogram: One reduction per pass
- Scan: Similar to current reduction
- Permute: Full data copy per pass
- **Critical**: This is the most expensive part

**Construction** (1 pass):
- Parallel over N-1 nodes
- Each node does O(log N) work for binary search
- **Moderate cost**

**Refit** (log N passes):
- Similar to current pyramid reduction
- **Light cost**

**Traversal** (1 pass):
- Per-particle work depends on theta and distribution
- Morton order improves cache coherence
- **Dominant runtime**, but more efficient than fixed stencils

### Optimization Opportunities

**Sort**:
- Use GPU-optimized radix sort (e.g., from research literature)
- Consider sorting only every K frames if particles move slowly
- Hybrid: refit existing tree without resort (faster but less stable)

**Traversal**:
- Early termination when accumulated force converges
- Process particles in batches for better divergence handling
- Precomputed MAC bounds per node

**Cache coherence**:
- Traverse particles in Morton order (already sorted)
- Layout nodes in breadth-first order for better cache lines
- Use texture compression if supported

---

## 14) Staged Implementation Strategy

### Phase 1: Infrastructure
- Morton encoding pass (verify bit patterns)
- Simple counting sort for testing (replace with radix later)
- Verify sorted order preserves spatial locality

### Phase 2: Tree Construction
- LCP-based node construction
- Validate tree structure (every particle reachable, correct parent/child links)
- Visualize tree (depth map, node occupancy)

### Phase 3: Multipoles
- Leaf initialization from particles
- Bottom-up refit with monopoles only
- Verify mass conservation at each level

### Phase 4: Traversal
- Simple monopole-only traversal
- Compare forces with current system (should be very similar)
- Profile performance

### Phase 5: Optimization
- Add quadrupoles for accuracy
- Implement proper radix sort
- Tune theta and MAC parameters
- Optimize traversal (early exit, batching)

### Phase 6: Integration
- Make LBVH default method
- Remove or archive old pyramid code
- Update documentation

---

## 15) Success Criteria

### Correctness Metrics

**Tree validity**:
- All N particles appear exactly once in leaves
- All N-1 internal nodes have exactly 2 children
- Root spans all particles
- No cycles in tree

**Physics accuracy**:
- Force magnitude matches current system ±10% (at same theta)
- Energy conservation on par with current system
- Momentum conservation better than current (due to consistent summation order)
- No "murmurations" or artificial flocking

**Stability**:
- Same particle configuration produces same tree (deterministic)
- Small position changes produce small tree changes
- Frame-to-frame force variation reduced

### Performance Targets

**Build time**: Faster than current `buildQuadtree()` (aggregation + reduction)
**Traversal time**: Comparable to current traversal for similar accuracy
**Memory**: Linear in N (advantage for small N, neutral for large N)
**Scalability**: Better scaling to N > 10,000 particles

### Quality of Life

**Debugging**: Visualize Morton order, tree depth, node bounds
**Profiling**: Per-stage timings (encode, sort, build, refit, traverse)
**Tuning**: Single theta parameter (like current), no magic constants

---

## 16) Risks and Mitigations

### Technical Risks

**Radix sort complexity**:
- **Risk**: GPU radix sort is tricky to implement efficiently
- **Mitigation**: Start with simpler sort (counting/bucket), optimize later
- **Fallback**: CPU-side sort for small N during development

**Stackless traversal**:
- **Risk**: Complex navigation logic, hard to debug
- **Mitigation**: Start with simple recursive traversal on CPU to validate logic
- **Fallback**: Use parent pointers, simpler to implement

**Floating-point precision**:
- **Risk**: Morton encoding quantization loses precision
- **Mitigation**: Use 60-bit codes (20 bits per axis), plenty of resolution
- **Fallback**: Keep original positions, use Morton only for ordering

**Divergence in traversal**:
- **Risk**: Different particles traverse different tree paths (GPU divergence)
- **Mitigation**: Process particles in Morton order (coherent paths)
- **Fallback**: Accept divergence, still faster than current stencils

### Practical Risks

**Development time**:
- **Risk**: More complex than expected, takes months
- **Mitigation**: Phased approach, validate each stage
- **Fallback**: Keep current system running in parallel

**Debugging difficulty**:
- **Risk**: Hard to visualize/debug tree structure on GPU
- **Mitigation**: Build CPU reference implementation first
- **Fallback**: Extensive logging and visualization tools

**Performance worse than expected**:
- **Risk**: Sort overhead dominates savings
- **Mitigation**: Profile early and often
- **Fallback**: Sort less frequently (every K frames)

---

## 17) Comparison with Plan B (Spectral) and Plan C (Quadrupole)

### When to Choose LBVH (Plan A)

**Advantages over Spectral (Plan B)**:
- No FFT complexity or k-space math
- Handles non-periodic boundaries naturally
- Better for sparse/clustered distributions
- True O(N log N) worst-case

**Advantages over Quadrupole Grid (Plan C)**:
- Adaptive to particle distribution
- No empty voxels
- Better cache coherence (Morton order)
- Long-term maintainable (research-backed structure)

**Disadvantages vs Spectral**:
- No smooth far-field (still has BH discreteness)
- More complex to implement
- Sort overhead every frame (or every K frames)

**Disadvantages vs Quadrupole Grid**:
- Requires radix sort
- More complex tree construction
- Larger code change

### Hybrid Possibilities

**TreePM with LBVH**:
- Use LBVH for near/mid range (adaptive tree)
- Use FFT for ultra-long range (smooth far-field)
- Best of both worlds for large N

**LBVH + Improved MAC**:
- Build LBVH structure
- Use improved MAC and quadrupoles from Plan C
- Get adaptivity AND accuracy

---

## 18) Open Research Questions

### Sort Frequency
**Question**: How often must we resort particles?  
**Options**:
- Every frame (most stable, most expensive)
- Every K frames (amortize cost)
- Only when topology degrades (adaptive)

**Investigation needed**: Measure tree quality degradation vs particle displacement.

### Node Layout Optimization
**Question**: What is optimal memory layout for nodes?  
**Options**:
- Array of structures (current description)
- Structure of arrays (better coalescing)
- Breadth-first vs depth-first ordering

**Investigation needed**: Profile cache hit rates for different layouts.

### Traversal Order
**Question**: Should we process particles in Morton order during traversal?  
**Hypothesis**: Yes, improves cache coherence  
**Investigation needed**: Benchmark with and without Morton ordering.

### Hybrid Depth Strategy
**Question**: Can we use LBVH for some depth, grid for rest?  
**Example**: LBVH to 4³ resolution, then switch to grid near-field  
**Investigation needed**: Complexity vs performance trade-off.

---

## 19) Reference Implementation Touchpoints

### Existing Code to Study

**For bit manipulation**:
- WebGL2 bitwise operators in GLSL ES 3.00
- See `bit-reverse.frag.js` for bit operations example

**For parallel reductions**:
- `reduction.frag.js` - hierarchical sum pattern
- `reduction-array.frag.js` - array-based reduction
- Adapt for scan (exclusive prefix sum)

**For tree traversal patterns**:
- `traversal.frag.js` - fixed stencil iteration
- `traversal-quadrupole.frag.js` - multipole evaluation
- Convert to variable-depth adaptive traversal

**For particle addressing**:
- `aggregation.vert.js` - particle ID to texture coordinate
- Reuse for accessing reordered particles

**For multipole computation**:
- `aggregation.frag.js` - stores mass and COM
- Extend to quadrupoles if needed

### Existing Infrastructure to Reuse

**Textures and FBOs**:
- `createRenderTexture`, `createPingPongTextures` from `common.js`
- Use for Morton keys, sorted data, tree nodes

**Shader compilation**:
- `createProgram` from `common.js`
- Same pattern for all new shaders

**Profiling**:
- `GPUProfiler` from `gpu-profiler.js`
- Wrap each stage (encode, sort passes, build, refit, traverse)

**Debug helpers**:
- `unbindAllTextures`, `checkGl`, `checkFBO` from `debug.js`
- Use between passes to catch errors

**Integration**:
- `integratePhysics` from `integrator.js`
- Unchanged, just different force input

---

## 20) Conceptual Shader Inventory

This is not a prescription of file structure, but suggested shader **functionality** needed:

### Morton Encoding
- **Purpose**: Position (xyz) → Morton key
- **Type**: Fullscreen or point-draw per particle
- **Inputs**: Position texture, world bounds
- **Outputs**: Morton key texture

### Radix Sort - Histogram
- **Purpose**: Count digit occurrences
- **Type**: Reduction over particles
- **Inputs**: Morton keys, current digit position
- **Outputs**: 256-bin histogram

### Radix Sort - Scan
- **Purpose**: Exclusive prefix sum
- **Type**: Multi-pass reduction (up-sweep then down-sweep)
- **Inputs**: Histogram
- **Outputs**: Cumulative offsets

### Radix Sort - Permute
- **Purpose**: Scatter particles to sorted positions
- **Type**: Fullscreen or point-draw per particle
- **Inputs**: Morton keys, scan results, unsorted data
- **Outputs**: Sorted particle data

### Tree Construction
- **Purpose**: Build internal node structure via LCP
- **Type**: Fullscreen, one fragment per internal node
- **Inputs**: Sorted Morton keys
- **Outputs**: Node texture (ranges, child pointers)

### Multipole Refit - Leaves
- **Purpose**: Initialize leaf nodes from particles
- **Type**: Fullscreen, one fragment per particle
- **Inputs**: Sorted particle data
- **Outputs**: Leaf node multipoles

### Multipole Refit - Internal
- **Purpose**: Bottom-up accumulation
- **Type**: Fullscreen, one fragment per internal node at current level
- **Inputs**: Child node multipoles, node structure
- **Outputs**: Parent node multipoles

### Force Traversal
- **Purpose**: Evaluate forces via LBVH
- **Type**: Fullscreen or point-draw per particle
- **Inputs**: Particle positions, tree structure, node multipoles
- **Outputs**: Force texture
- **Logic**: Stackless traversal with MAC, multipole evaluation

### (Optional) Near-Field Direct
- **Purpose**: Local direct particle-particle
- **Type**: Fragment per particle
- **Inputs**: Particle positions, neighbor list or grid
- **Outputs**: Additive to force texture

---

## 21) Conceptual Validation Tools

### Tree Validator
- Traverse tree, verify all particles reached exactly once
- Check parent-child consistency
- Verify mass conservation at each level
- Output: Pass/fail per frame

### Morton Order Visualizer
- Color particles by Morton code (rainbow map)
- Should show spatial clustering
- Discontinuities indicate potential issues

### Depth Map Visualizer
- Color particles by leaf depth
- Uniform depth = balanced tree
- Extreme variation = degenerate cases

### Force Comparator
- Run same frame with LBVH and current method
- Compute per-particle force difference
- Histogram of relative errors
- Should be small (few %) at same theta

### Performance Profiler
- Per-stage GPU timings
- Frame-to-frame variance
- Compare total cost vs current system
- Identify bottlenecks

---

## 22) Mathematical Foundations

### Space-Filling Curves
Morton order is a **discrete approximation** of the Hilbert curve. Both map 3D space to 1D while preserving locality, but Morton is simpler to compute (bit interleaving vs state machine).

**Locality preservation**: Points close in 3D have close Morton codes, though not perfectly (Hilbert is better but harder to compute).

### LCP and Tree Structure
The **common prefix length** between adjacent Morton codes in sorted order equals the tree depth of their lowest common ancestor:
```
prefix_length = clz(morton[i] XOR morton[i+1])
```

This implicit encoding eliminates need for explicit pointer structures.

### Barnes-Hut Opening Criterion
Standard criterion: `s/d < θ` where:
- `s` = node size (bounding box diagonal or sphere radius)
- `d` = distance from node COM to target particle
- `θ` = accuracy parameter (0.5-0.7 typical)

Improved criterion (from Plan C):
```
d > s/θ + δ_COM
```
Where `δ_COM` is distance from node COM to node center, accounting for asymmetric mass distribution.

### Multipole Expansion
**Monopole**: Point mass approximation
```
Φ(r) = -G·M/|r|
F(r) = -G·M·r/|r|³
```

**Quadrupole correction**: Second-order tensor
```
Φ_quad(r) = (1/2) Σ_ij Q_ij · r_i · r_j / |r|⁵
F_quad(r) = -∇Φ_quad(r)
```

Reduces error for elongated or asymmetric distributions.

---

## 23) Implementation Checklist

### Prerequisites
- [ ] Verify WebGL2 support for bitwise operations
- [ ] Confirm R32UI/RG32UI texture support
- [ ] Test atomic operations if using iterative refit
- [ ] Measure current system baseline (time, accuracy)

### Morton Encoding
- [ ] Implement bit interleaving function (10-bit per axis)
- [ ] Validate Morton codes preserve spatial order
- [ ] Test edge cases (boundaries, identical positions)
- [ ] Profile encoding time

### Radix Sort
- [ ] Implement histogram pass
- [ ] Implement scan (prefix sum)
- [ ] Implement permute pass
- [ ] Validate sort correctness (sorted order, stability)
- [ ] Profile sort time (all passes)
- [ ] Optimize: reduce passes, better coalescing

### Tree Construction
- [ ] Implement LCP/delta function
- [ ] Implement internal node construction
- [ ] Validate tree structure (connectivity, no cycles)
- [ ] Visualize tree depth distribution
- [ ] Profile construction time

### Multipole Refit
- [ ] Initialize leaf nodes from particles
- [ ] Implement bottom-up reduction (monopole)
- [ ] Validate mass conservation
- [ ] (Optional) Add quadrupole computation
- [ ] Profile refit time

### Traversal
- [ ] Implement stackless navigation
- [ ] Implement opening criterion
- [ ] Implement monopole force evaluation
- [ ] (Optional) Add quadrupole evaluation
- [ ] Validate forces vs current system
- [ ] Profile traversal time

### Integration
- [ ] Wire into ParticleSystem.step()
- [ ] Add method option 'lbvh'
- [ ] Reuse existing integration
- [ ] Test with existing demos
- [ ] Compare stability with current system

---

## 24) Conclusion

Plan A (LBVH with Morton order) is a **sophisticated but well-understood approach** to adaptive spatial hierarchies on GPU. It addresses the fundamental limitations of the current fixed-grid pyramid:

**Key Benefits**:
- Adaptive to particle distribution
- Stable summation order
- Cache-coherent access
- Research-proven structure

**Key Challenges**:
- Complex implementation (sort, LCP, traversal)
- Sort overhead (mitigated by amortization)
- Debugging difficulty (mitigated by validation tools)

**Bottom Line**: LBVH is the most technically ambitious of the three plans, but offers the best long-term foundation for a scalable, maintainable N-body solver. It combines the adaptive accuracy of tree methods with the GPU-friendly flat memory layout of modern acceleration structures.

**Recommendation**: Implement in phases, validate each stage thoroughly, and maintain current system in parallel until LBVH proves superior in both performance and stability metrics.
